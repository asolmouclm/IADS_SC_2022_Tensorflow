{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3 notebook part 1: MNIST classifier\n",
    "\n",
    "## Introduction to TensorFlow and Deep Learning\n",
    "\n",
    "## IADS Summer School, 1st August 2022\n",
    "\n",
    "### Dr Michael Fairbank, University of Essex, UK\n",
    "\n",
    "- Email: m.fairbank@essex.ac.uk\n",
    "- This is a Jupyter Notebook to accompany Lecture 3 of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digits dataset\n",
    "\n",
    "- First load and view the MNIST digits dataset\n",
    "- There are 60000 images in this dataset, but we will only view the first 25 of them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load and visualise the MNIST digits\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images0, train_labels0),(test_images0, test_labels0) = mnist.load_data()\n",
    "\n",
    "print(\"test_images shape\",test_images0.shape,\"train_images shape\",train_images0.shape)\n",
    "class_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "import matplotlib.pyplot as plt\n",
    "# plot first few images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    # define subplot\n",
    "    plt.subplot(5,5,i+1)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(train_images0[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # Add a label underneath...\n",
    "    plt.xlabel(class_names[train_labels0[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next build a neural-network classifier for these digits.\n",
    "\n",
    "- We will build a keras model, with the higher-level API concepts, taught in lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Each MNIST images are 28*28.  Therefore if there are N images, then the \n",
    "# shape of the numpy array holding the images is N*28*28\n",
    "# We will reshape that here to be N*784, using a numpy reshape.\n",
    "# Note that this flattens each image into a single vector length 784.\n",
    "test_images=test_images0.reshape(10000,784) # 10000 test patterns\n",
    "train_images=train_images0.reshape(60000,784) # 60000 train patterns\n",
    "\n",
    "# Also rescale greyscale from 8 bit to floating point (by dividing by 255)\n",
    "test_images=test_images/255.0\n",
    "train_images=train_images/255.0 \n",
    "\n",
    "# Create the model\n",
    "layer1=keras.layers.Dense(10, activation=\"softmax\")\n",
    "keras_model=keras.models.Sequential(layer1)\n",
    "keras_model.build(input_shape=[None,784])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the keras model summary information\n",
    "\n",
    "- This shows you how many layers your neural network has, and how many weights, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# View the model summary information...\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Keras model\n",
    "\n",
    "- We will use SGD optimiser (ordinary gradient descent)\n",
    "- We will use Cross Entropy loss (\"SparseCategoricalCrossentropy\")\n",
    "- We will run 200 training iterations (epochs)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(0.5)\n",
    "keras_model.compile(\n",
    "    optimizer=optimizer,  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ") \n",
    "# Train loop\n",
    "history = keras_model.fit(\n",
    "    train_images,\n",
    "    train_labels0,\n",
    "    batch_size=len(train_images),\n",
    "    epochs=200,\n",
    "    validation_data=(test_images, test_labels0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the training performance\n",
    "\n",
    "- When the Keras fit loop runs, it returns a \"history\" object, which includes a dictionary of the trianing history.\n",
    "\n",
    "- Hence we can plot graphs of the training performance (Accuracy, Loss), for both the \"Training\" and \"Validation\" sets...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first show keys for data series recorded by fit loop:\n",
    "for item in history.history:\n",
    "    print(\"Key:\",item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'],label=\"train\")\n",
    "plt.plot(history.history['val_loss'],label=\"validation\")\n",
    "plt.title('Model Loss')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#print(\"history\",history.history)\n",
    "plt.plot(history.history['sparse_categorical_accuracy'],label=\"train\")\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'],label=\"validation\")\n",
    "plt.title('Model Accuracy')\n",
    "#plt.yscale('log')\n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Iteration')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect how well the system is working on a sample of 25 new images (from the test set)...\n",
    "- The test set has a lot of images in it, but we can only view 25 at a time.\n",
    "- Hence rerun this code block several times, to get a different random set of samples from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10,10))\n",
    "# plot 25 random images from the test set.\n",
    "first_index=np.random.randint(len(test_images)-25)\n",
    "for i in range(first_index,first_index+25):\n",
    "    # define subplot\n",
    "    plt.subplot(5,5,i+1-first_index)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(test_images0[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    if class_names!=None:\n",
    "        prediction=keras_model(test_images[i:i+1])[0,:] # This will be a vector of length 10\n",
    "        prediction_class=np.argmax(prediction)  # Pick the index of the largest element of the length-10 vector\n",
    "        # Add a label underneath...\n",
    "        true_label=test_labels0[i]\n",
    "        class_name=class_names[prediction_class]\n",
    "        plt.xlabel(class_name+\" \"+(\"CORRECT\" if prediction_class==true_label else \"WRONG\"))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
